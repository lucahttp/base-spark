{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucahttp/base-spark/blob/master/demo/vibevoice_realtime_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WvIaUJD2y0yU",
      "metadata": {
        "id": "WvIaUJD2y0yU"
      },
      "source": [
        "# VibeVoice-Realtime Colab — T4 Quickstart\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8fTKYGx7DZk",
      "metadata": {
        "id": "e8fTKYGx7DZk"
      },
      "source": [
        "## Step 1: Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4wxJ6QHM-ZOb",
      "metadata": {
        "id": "4wxJ6QHM-ZOb"
      },
      "outputs": [],
      "source": [
        "# Check for T4 GPU\n",
        "import torch\n",
        "if torch.cuda.is_available() and \"T4\" in torch.cuda.get_device_name(0):\n",
        "    print(\"✅ T4 GPU detected\")\n",
        "else:\n",
        "    print(\"\"\"\n",
        "    ⚠️ WARNING: T4 GPU not detected\n",
        "\n",
        "    The recommended runtime for this Colab notebook is \"T4 GPU\".\n",
        "\n",
        "    To change the runtime type:\n",
        "\n",
        "        1. Click on \"Runtime\" in the top navigation menu\n",
        "        2. Click on \"Change runtime type\"\n",
        "        3. Select \"T4 GPU\"\n",
        "        4. Click \"OK\" if a \"Disconnect and delete runtime\" window appears\n",
        "        5. Click on \"Save\"\n",
        "\n",
        "    \"\"\")\n",
        "\n",
        "# Clone the VibeVoice repository\n",
        "![ -d /content/VibeVoice ] || git clone --quiet --branch main --depth 1 https://github.com/microsoft/VibeVoice.git /content/VibeVoice\n",
        "print(\"✅ Cloned VibeVoice repository\")\n",
        "\n",
        "# Install project dependencies\n",
        "!uv pip --quiet install --system -e /content/VibeVoice\n",
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O cloudflared && chmod +x cloudflared\n",
        "print(\"✅ Installed dependencies\")\n",
        "\n",
        "# Download model\n",
        "from huggingface_hub import snapshot_download\n",
        "snapshot_download(\"microsoft/VibeVoice-Realtime-0.5B\", local_dir=\"/content/models/VibeVoice-Realtime-0.5B\")\n",
        "print(\"✅ Downloaded model: microsoft/VibeVoice-Realtime-0.5B\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88c727ab",
      "metadata": {
        "id": "88c727ab"
      },
      "source": [
        "[Optional] If the download exceeds 1 minute, it is probably stuck. You can: (1) interrupt the execution, (2) log in to Hugging Face, and (3) try download again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dec6b870",
      "metadata": {
        "id": "dec6b870"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c579654b",
      "metadata": {
        "id": "c579654b"
      },
      "outputs": [],
      "source": [
        "snapshot_download(\"microsoft/VibeVoice-Realtime-0.5B\", local_dir=\"/content/models/VibeVoice-Realtime-0.5B\")\n",
        "print(\"✅ Downloaded model: microsoft/VibeVoice-Realtime-0.5B\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfe30d6f",
      "metadata": {
        "id": "dfe30d6f"
      },
      "source": [
        "[Optional] More experimental voices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb33c9ce",
      "metadata": {
        "id": "bb33c9ce"
      },
      "outputs": [],
      "source": [
        "!bash /content/VibeVoice/demo/download_experimental_voices.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pgKlV7153Ifi",
      "metadata": {
        "id": "pgKlV7153Ifi"
      },
      "source": [
        "## Step 2: Launch VibeVoice-Realtime Demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Yc1N9EHswFxA",
      "metadata": {
        "id": "Yc1N9EHswFxA"
      },
      "outputs": [],
      "source": [
        "import subprocess, re, time, threading\n",
        "\n",
        "srv = subprocess.Popen(\n",
        "    \"python /content/VibeVoice/demo/vibevoice_realtime_demo.py --model_path /content/models/VibeVoice-Realtime-0.5B --port 8000\",\n",
        "    shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1, universal_newlines=True,\n",
        ")\n",
        "cf = subprocess.Popen(\n",
        "    \"./cloudflared tunnel --url http://localhost:8000 --no-autoupdate\",\n",
        "    shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1, universal_newlines=True,\n",
        ")\n",
        "\n",
        "public_url = None\n",
        "server_ready = False\n",
        "url_pattern  = re.compile(r\"(https://[a-z0-9-]+\\.trycloudflare\\.com)\")\n",
        "\n",
        "def read_srv():\n",
        "    global server_ready\n",
        "    for ln in srv.stdout:\n",
        "        print(ln.strip())\n",
        "        if \"Uvicorn running on\" in ln:\n",
        "            server_ready = True\n",
        "\n",
        "def read_cf():\n",
        "    global public_url\n",
        "    for ln in cf.stdout:\n",
        "        m = url_pattern.search(ln)\n",
        "        if m:\n",
        "            public_url = m.group(1)\n",
        "            break\n",
        "\n",
        "threading.Thread(target=read_srv, daemon=True).start()\n",
        "threading.Thread(target=read_cf,  daemon=True).start()\n",
        "\n",
        "\n",
        "while True:\n",
        "    if server_ready and public_url:\n",
        "        print(f\"✅ Public URL: {public_url}\\n\");\n",
        "        public_url = None\n",
        "    time.sleep(0.25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f35bc87"
      },
      "source": [
        "# Task\n",
        "Integrate real-time Whisper transcription with VibeVoice synthesis, allowing the VibeVoice system to vocalize transcribed speech received via a microphone, and provide instructions on how to interact with the new real-time VibeVoice system."
      ],
      "id": "6f35bc87"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e4f151d"
      },
      "source": [
        "## Install Audio and Whisper Libraries\n",
        "\n",
        "### Subtask:\n",
        "Install necessary Python libraries for real-time audio input (e.g., `sounddevice`, `numpy`) and the `transformers` library for Whisper transcription.\n"
      ],
      "id": "2e4f151d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ec4f4ae"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires installing specific Python libraries. I will use the `uv pip install` command to install `sounddevice`, `numpy`, and `transformers`.\n",
        "\n"
      ],
      "id": "3ec4f4ae"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "139a6c7d",
        "outputId": "9c292569-9cf4-42cc-c13a-dc1a1580e9a7"
      },
      "source": [
        "print(\"Installing audio and Whisper libraries...\")\n",
        "!uv pip install --quiet --system sounddevice numpy transformers\n",
        "print(\"✅ Installed sounddevice, numpy, and transformers\")"
      ],
      "id": "139a6c7d",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing audio and Whisper libraries...\n",
            "✅ Installed sounddevice, numpy, and transformers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b375ae4"
      },
      "source": [
        "## Modify VibeVoice Real-time Demo Script\n",
        "\n",
        "### Subtask:\n",
        "Modify the `/content/VibeVoice/demo/vibevoice_realtime_demo.py` file to integrate real-time audio capture, Whisper transcription, and feed the transcribed text to VibeVoice for synthesis. This will involve setting up a microphone input stream, processing audio chunks with Whisper, and routing the output to the VibeVoice engine for speech generation and playback.\n"
      ],
      "id": "7b375ae4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9deefb08"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires modifying an existing Python script (`/content/VibeVoice/demo/vibevoice_realtime_demo.py`) to integrate real-time audio capture, Whisper transcription, and VibeVoice synthesis. Since the original content of this file is not accessible, I will provide a comprehensive replacement script that incorporates a FastAPI server (as implied by the previous `Uvicorn running` output), loads the VibeVoice model, and adds the specified real-time audio and Whisper functionality in separate threads. This script will include all necessary imports, Whisper model loading, an audio callback for `sounddevice`, a transcription loop, and a VibeVoice synthesis loop, along with graceful shutdown mechanisms.\n",
        "\n"
      ],
      "id": "9deefb08"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "dbde64cd",
        "outputId": "3a543c61-9375-4354-d92e-3bdbad2529bf"
      },
      "source": [
        "%%writefile /content/VibeVoice/demo/vibevoice_realtime_demo.py\n",
        "import sounddevice as sd\n",
        "import numpy as np\n",
        "import threading\n",
        "import time\n",
        "import queue\n",
        "import argparse\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "import torch\n",
        "import os\n",
        "\n",
        "# FastAPI imports\n",
        "from fastapi import FastAPI, WebSocket, WebSocketDisconnect\n",
        "from pydantic import BaseModel\n",
        "import uvicorn\n",
        "\n",
        "# Placeholder for VibeVoice model and processor\n",
        "_vibevoice_model = None\n",
        "_vibevoice_processor = None\n",
        "_vibevoice_device = None\n",
        "\n",
        "# Argument parsing for model path\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--model_path\", type=str, required=True, help=\"Path to the VibeVoice model\")\n",
        "parser.add_argument(\"--port\", type=int, default=8000, help=\"Port to run the FastAPI app on\")\n",
        "args = parser.parse_args()\n",
        "\n",
        "# --- VibeVoice Model Loading ---\n",
        "def load_vibevoice_model_and_processor(model_path):\n",
        "    global _vibevoice_model, _vibevoice_processor, _vibevoice_device\n",
        "    if _vibevoice_model is None or _vibevoice_processor is None:\n",
        "        print(f\"Attempting to load VibeVoice model from {model_path}...\")\n",
        "        try:\n",
        "            # Assuming VibeVoice library is installed and has similar APIs to Hugging Face models\n",
        "            # The actual import path might need adjustment based on VibeVoice repository structure\n",
        "            from VibeVoice import VibeVoiceModel, VibeVoiceProcessor\n",
        "            _vibevoice_processor = VibeVoiceProcessor.from_pretrained(model_path)\n",
        "            _vibevoice_model = VibeVoiceModel.from_pretrained(model_path)\n",
        "            _vibevoice_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "            _vibevoice_model.to(_vibevoice_device)\n",
        "            _vibevoice_model.eval() # Set model to evaluation mode\n",
        "            print(\"VibeVoice model loaded successfully.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading VibeVoice model: {e}\")\n",
        "            print(\"VibeVoice model loading failed. VibeVoice synthesis will be mocked.\")\n",
        "            _vibevoice_processor = None\n",
        "            _vibevoice_model = None\n",
        "            _vibevoice_device = None\n",
        "\n",
        "# Call this at script start to load VibeVoice\n",
        "load_vibevoice_model_and_processor(args.model_path)\n",
        "\n",
        "# --- Whisper Integration ---\n",
        "print(\"Loading Whisper model...\")\n",
        "whisper_processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny.en\")\n",
        "whisper_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny.en\")\n",
        "whisper_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "whisper_model.to(whisper_device)\n",
        "whisper_model.eval()\n",
        "print(\"Whisper model loaded.\")\n",
        "\n",
        "# Audio parameters for sounddevice and Whisper\n",
        "SAMPLE_RATE = 16000\n",
        "CHANNELS = 1\n",
        "DTYPE = 'float32'\n",
        "BLOCK_SIZE = 1024 # Buffer size for sounddevice callback\n",
        "AUDIO_CHUNK_SIZE = SAMPLE_RATE * 5 # Process 5 seconds of audio at a time for Whisper\n",
        "\n",
        "audio_buffer_raw = queue.Queue() # Queue to pass raw audio blocks from callback to transcription thread\n",
        "transcription_queue = queue.Queue() # To pass transcriptions to VibeVoice synthesis thread\n",
        "stop_event = threading.Event()\n",
        "\n",
        "def audio_callback(indata, frames, time_info, status):\n",
        "    if status:\n",
        "        print(f\"Sounddevice status: {status}\", flush=True)\n",
        "    audio_buffer_raw.put(indata[:, 0].copy()) # .copy() to ensure data ownership\n",
        "\n",
        "# Full audio buffer for Whisper to accumulate\n",
        "full_audio_buffer = np.array([], dtype=DTYPE)\n",
        "full_audio_buffer_lock = threading.Lock()\n",
        "\n",
        "def transcription_loop():\n",
        "    global full_audio_buffer\n",
        "    print(\"Transcription thread started.\")\n",
        "    while not stop_event.is_set():\n",
        "        try:\n",
        "            # Get audio chunks from the queue and append to full_audio_buffer\n",
        "            while not audio_buffer_raw.empty():\n",
        "                chunk = audio_buffer_raw.get()\n",
        "                with full_audio_buffer_lock:\n",
        "                    full_audio_buffer = np.append(full_audio_buffer, chunk)\n",
        "\n",
        "            # Process a segment if enough audio is accumulated\n",
        "            if len(full_audio_buffer) >= AUDIO_CHUNK_SIZE:\n",
        "                with full_audio_buffer_lock:\n",
        "                    segment = full_audio_buffer[:AUDIO_CHUNK_SIZE]\n",
        "                    full_audio_buffer = full_audio_buffer[AUDIO_CHUNK_SIZE:]\n",
        "\n",
        "                try:\n",
        "                    # Move to device if available\n",
        "                    input_features = whisper_processor(segment, sampling_rate=SAMPLE_RATE, return_tensors=\"pt\").input_features\n",
        "                    input_features = input_features.to(whisper_device)\n",
        "                    predicted_ids = whisper_model.generate(input_features)\n",
        "                    transcription = whisper_processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
        "                    if transcription.strip() != \"\":\n",
        "                        print(f\"Transcribed: {transcription}\", flush=True)\n",
        "                        transcription_queue.put(transcription)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error during Whisper transcription: {e}\", flush=True)\n",
        "            else:\n",
        "                time.sleep(0.1) # Short sleep to avoid busy-waiting\n",
        "\n",
        "        except queue.Empty:\n",
        "            time.sleep(0.05)\n",
        "        except Exception as e:\n",
        "            print(f\"Error in transcription loop: {e}\", flush=True)\n",
        "\n",
        "    # Process any remaining audio in buffer before stopping\n",
        "    if len(full_audio_buffer) > 0:\n",
        "        with full_audio_buffer_lock:\n",
        "            remaining_segment = full_audio_buffer\n",
        "            full_audio_buffer = np.array([], dtype=DTYPE)\n",
        "        try:\n",
        "            if len(remaining_segment) > 0:\n",
        "                input_features = whisper_processor(remaining_segment, sampling_rate=SAMPLE_RATE, return_tensors=\"pt\").input_features\n",
        "                input_features = input_features.to(whisper_device)\n",
        "                predicted_ids = whisper_model.generate(input_features)\n",
        "                transcription = whisper_processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
        "                if transcription.strip() != \"\":\n",
        "                    print(f\"Final Transcribed: {transcription}\", flush=True)\n",
        "                    transcription_queue.put(transcription)\n",
        "        except Exception as e:\n",
        "            print(f\"Error during final transcription: {e}\", flush=True)\n",
        "    print(\"Transcription thread stopped.\")\n",
        "\n",
        "\n",
        "# --- VibeVoice Synthesis and Playback ---\n",
        "# This function encapsulates the core VibeVoice text-to-speech logic\n",
        "def _synthesize_and_play(text: str):\n",
        "    if not _vibevoice_model or not _vibevoice_processor:\n",
        "        print(f\"VibeVoice model not loaded, mocking synthesis for: '{text}'\", flush=True)\n",
        "        # Simulate some delay for synthesis\n",
        "        time.sleep(len(text) * 0.05)\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # Example VibeVoice synthesis process - actual API might differ\n",
        "        inputs = _vibevoice_processor(text=text, return_tensors=\"pt\").to(_vibevoice_device)\n",
        "        with torch.no_grad():\n",
        "            audio_array = _vibevoice_model.generate(**inputs).cpu().numpy().squeeze()\n",
        "\n",
        "        # Play the synthesized audio\n",
        "        print(f\"Playing VibeVoice synthesized audio for: '{text}'\", flush=True)\n",
        "        sd.play(audio_array, samplerate=_vibevoice_processor.sampling_rate)\n",
        "        sd.wait() # Wait for playback to finish\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during VibeVoice synthesis or playback: {e}\", flush=True)\n",
        "\n",
        "def vibevoice_synthesis_loop():\n",
        "    print(\"VibeVoice synthesis thread started.\")\n",
        "    while not stop_event.is_set():\n",
        "        try:\n",
        "            text_to_synthesize = transcription_queue.get(timeout=0.1) # Get with timeout\n",
        "            if text_to_synthesize:\n",
        "                print(f\"VibeVoice synthesizing: '{text_to_synthesize}'\", flush=True)\n",
        "                _synthesize_and_play(text_to_synthesize)\n",
        "        except queue.Empty:\n",
        "            pass # No transcription yet, continue looping\n",
        "        except Exception as e:\n",
        "            print(f\"Error in VibeVoice synthesis loop: {e}\", flush=True)\n",
        "    print(\"VibeVoice synthesis thread stopped.\")\n",
        "\n",
        "# --- FastAPI Application Setup ---\n",
        "app = FastAPI()\n",
        "\n",
        "class TextPayload(BaseModel):\n",
        "    text: str\n",
        "\n",
        "@app.post(\"/synthesize\")\n",
        "async def synthesize_text_api(payload: TextPayload):\n",
        "    # This endpoint allows external text to be synthesized\n",
        "    print(f\"API received text for synthesis: {payload.text}\", flush=True)\n",
        "    # The API call will also go through the internal synthesis logic\n",
        "    _synthesize_and_play(payload.text)\n",
        "    return {\"message\": f\"Synthesis request received for: {payload.text}\"}\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def root():\n",
        "    return {\"message\": \"VibeVoice Real-time Demo with Whisper integration is running!\"}\n",
        "\n",
        "# --- Main execution block ---\n",
        "# These threads need to be started before uvicorn.run blocks the main thread.\n",
        "transcription_thread = threading.Thread(target=transcription_loop, daemon=True)\n",
        "vibevoice_synthesis_thread = threading.Thread(target=vibevoice_synthesis_loop, daemon=True)\n",
        "\n",
        "@app.on_event(\"startup\")\n",
        "async def startup_event():\n",
        "    print(\"FastAPI startup event: Starting audio stream and threads...\")\n",
        "    global audio_stream\n",
        "    try:\n",
        "        audio_stream = sd.InputStream(\n",
        "            samplerate=SAMPLE_RATE,\n",
        "            channels=CHANNELS,\n",
        "            dtype=DTYPE,\n",
        "            blocksize=BLOCK_SIZE,\n",
        "            callback=audio_callback\n",
        "        )\n",
        "        audio_stream.start()\n",
        "        print(\"Audio input stream started.\")\n",
        "        transcription_thread.start()\n",
        "        vibevoice_synthesis_thread.start()\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to start audio stream or threads on startup: {e}\", flush=True)\n",
        "\n",
        "@app.on_event(\"shutdown\")\n",
        "async def shutdown_event():\n",
        "    print(\"FastAPI shutdown event: Stopping audio stream and threads...\")\n",
        "    stop_event.set()\n",
        "    if 'audio_stream' in globals() and audio_stream.is_active:\n",
        "        audio_stream.stop()\n",
        "        audio_stream.close()\n",
        "    if transcription_thread.is_alive():\n",
        "        transcription_thread.join(timeout=5)\n",
        "    if vibevoice_synthesis_thread.is_alive():\n",
        "        vibevoice_synthesis_thread.join(timeout=5)\n",
        "    print(\"Cleanup complete.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Uvicorn needs to be run programmatically to allow startup/shutdown events\n",
        "    print(f\"Starting Uvicorn server on port {args.port}...\")\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=args.port)\n"
      ],
      "id": "dbde64cd",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/VibeVoice/demo/vibevoice_realtime_demo.py\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/VibeVoice/demo/vibevoice_realtime_demo.py'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1128443140.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'writefile'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/VibeVoice/demo/vibevoice_realtime_demo.py'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'import sounddevice as sd\\nimport numpy as np\\nimport threading\\nimport time\\nimport queue\\nimport argparse\\nfrom transformers import WhisperProcessor, WhisperForConditionalGeneration\\nimport torch\\nimport os\\n\\n# FastAPI imports\\nfrom fastapi import FastAPI, WebSocket, WebSocketDisconnect\\nfrom pydantic import BaseModel\\nimport uvicorn\\n\\n# Placeholder for VibeVoice model and processor\\n_vibevoice_model = None\\n_vibevoice_processor = None\\n_vibevoice_device = None\\n\\n# Argument parsing for model path\\nparser = argparse.ArgumentParser()\\nparser.add_argument(\"--model_path\", type=str, required=True, help=\"Path to the VibeVoice model\")\\nparser.add_argument(\"--port\", type=int, default=8000, help=\"Port to run the FastAPI app on\")\\nargs = parser.parse_args()\\n\\n# --- VibeVoice Model Loading ---\\ndef load_vibevoice_model_and_processor(model_path):\\n    global _vibevoice_model, _vibevoice_processor, _vibevoice_device\\n    if _vibevoice_model is None or _vibevoice_processor is None:\\n        print(f\"Attempting to load VibeVoice model from {model_path}...\")\\n        try:\\n            # Assuming VibeVoice library is installed and has similar APIs to Hugging Face models\\n            # The actual import path might need adjustment based on VibeVoice repository s...\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-98>\u001b[0m in \u001b[0;36mwritefile\u001b[0;34m(self, line, cell)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magics/osm.py\u001b[0m in \u001b[0;36mwritefile\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'a'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/VibeVoice/demo/vibevoice_realtime_demo.py'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aebed84"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous `%%writefile` command failed because the directory `/content/VibeVoice/demo/` did not exist. I need to create this directory first before attempting to write the file.\n",
        "\n"
      ],
      "id": "8aebed84"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f1a2f73",
        "outputId": "7829b223-e005-45cf-c5b6-1f006978c4f1"
      },
      "source": [
        "import os\n",
        "os.makedirs('/content/VibeVoice/demo', exist_ok=True)\n",
        "print(\"✅ Directory /content/VibeVoice/demo created.\")"
      ],
      "id": "6f1a2f73",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Directory /content/VibeVoice/demo created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f20b1f3"
      },
      "source": [
        "**Reasoning**:\n",
        "The directory `/content/VibeVoice/demo` has now been created. I can now re-attempt to write the modified `vibevoice_realtime_demo.py` file to this location.\n",
        "\n"
      ],
      "id": "0f20b1f3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "985f4ff6",
        "outputId": "5f244a28-4dba-4d9e-e303-dd94ea4a91a6"
      },
      "source": [
        "%%writefile /content/VibeVoice/demo/vibevoice_realtime_demo.py\n",
        "import sounddevice as sd\n",
        "import numpy as np\n",
        "import threading\n",
        "import time\n",
        "import queue\n",
        "import argparse\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "import torch\n",
        "import os\n",
        "\n",
        "# FastAPI imports\n",
        "from fastapi import FastAPI, WebSocket, WebSocketDisconnect\n",
        "from pydantic import BaseModel\n",
        "import uvicorn\n",
        "\n",
        "# Placeholder for VibeVoice model and processor\n",
        "_vibevoice_model = None\n",
        "_vibevoice_processor = None\n",
        "_vibevoice_device = None\n",
        "\n",
        "# Argument parsing for model path\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--model_path\", type=str, required=True, help=\"Path to the VibeVoice model\")\n",
        "parser.add_argument(\"--port\", type=int, default=8000, help=\"Port to run the FastAPI app on\")\n",
        "args = parser.parse_args()\n",
        "\n",
        "# --- VibeVoice Model Loading ---\n",
        "def load_vibevoice_model_and_processor(model_path):\n",
        "    global _vibevoice_model, _vibevoice_processor, _vibevoice_device\n",
        "    if _vibevoice_model is None or _vibevoice_processor is None:\n",
        "        print(f\"Attempting to load VibeVoice model from {model_path}...\")\n",
        "        try:\n",
        "            # Assuming VibeVoice library is installed and has similar APIs to Hugging Face models\n",
        "            # The actual import path might need adjustment based on VibeVoice repository structure\n",
        "            from VibeVoice import VibeVoiceModel, VibeVoiceProcessor\n",
        "            _vibevoice_processor = VibeVoiceProcessor.from_pretrained(model_path)\n",
        "            _vibevoice_model = VibeVoiceModel.from_pretrained(model_path)\n",
        "            _vibevoice_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "            _vibevoice_model.to(_vibevoice_device)\n",
        "            _vibevoice_model.eval() # Set model to evaluation mode\n",
        "            print(\"VibeVoice model loaded successfully.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading VibeVoice model: {e}\")\n",
        "            print(\"VibeVoice model loading failed. VibeVoice synthesis will be mocked.\")\n",
        "            _vibevoice_processor = None\n",
        "            _vibevoice_model = None\n",
        "            _vibevoice_device = None\n",
        "\n",
        "# Call this at script start to load VibeVoice\n",
        "load_vibevoice_model_and_processor(args.model_path)\n",
        "\n",
        "# --- Whisper Integration ---\n",
        "print(\"Loading Whisper model...\")\n",
        "whisper_processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny.en\")\n",
        "whisper_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny.en\")\n",
        "whisper_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "whisper_model.to(whisper_device)\n",
        "whisper_model.eval()\n",
        "print(\"Whisper model loaded.\")\n",
        "\n",
        "# Audio parameters for sounddevice and Whisper\n",
        "SAMPLE_RATE = 16000\n",
        "CHANNELS = 1\n",
        "DTYPE = 'float32'\n",
        "BLOCK_SIZE = 1024 # Buffer size for sounddevice callback\n",
        "AUDIO_CHUNK_SIZE = SAMPLE_RATE * 5 # Process 5 seconds of audio at a time for Whisper\n",
        "\n",
        "audio_buffer_raw = queue.Queue() # Queue to pass raw audio blocks from callback to transcription thread\n",
        "transcription_queue = queue.Queue() # To pass transcriptions to VibeVoice synthesis thread\n",
        "stop_event = threading.Event()\n",
        "\n",
        "def audio_callback(indata, frames, time_info, status):\n",
        "    if status:\n",
        "        print(f\"Sounddevice status: {status}\", flush=True)\n",
        "    audio_buffer_raw.put(indata[:, 0].copy()) # .copy() to ensure data ownership\n",
        "\n",
        "# Full audio buffer for Whisper to accumulate\n",
        "full_audio_buffer = np.array([], dtype=DTYPE)\n",
        "full_audio_buffer_lock = threading.Lock()\n",
        "\n",
        "def transcription_loop():\n",
        "    global full_audio_buffer\n",
        "    print(\"Transcription thread started.\")\n",
        "    while not stop_event.is_set():\n",
        "        try:\n",
        "            # Get audio chunks from the queue and append to full_audio_buffer\n",
        "            while not audio_buffer_raw.empty():\n",
        "                chunk = audio_buffer_raw.get()\n",
        "                with full_audio_buffer_lock:\n",
        "                    full_audio_buffer = np.append(full_audio_buffer, chunk)\n",
        "\n",
        "            # Process a segment if enough audio is accumulated\n",
        "            if len(full_audio_buffer) >= AUDIO_CHUNK_SIZE:\n",
        "                with full_audio_buffer_lock:\n",
        "                    segment = full_audio_buffer[:AUDIO_CHUNK_SIZE]\n",
        "                    full_audio_buffer = full_audio_buffer[AUDIO_CHUNK_SIZE:]\n",
        "\n",
        "                try:\n",
        "                    # Move to device if available\n",
        "                    input_features = whisper_processor(segment, sampling_rate=SAMPLE_RATE, return_tensors=\"pt\").input_features\n",
        "                    input_features = input_features.to(whisper_device)\n",
        "                    predicted_ids = whisper_model.generate(input_features)\n",
        "                    transcription = whisper_processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
        "                    if transcription.strip() != \"\":\n",
        "                        print(f\"Transcribed: {transcription}\", flush=True)\n",
        "                        transcription_queue.put(transcription)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error during Whisper transcription: {e}\", flush=True)\n",
        "            else:\n",
        "                time.sleep(0.1) # Short sleep to avoid busy-waiting\n",
        "\n",
        "        except queue.Empty:\n",
        "            time.sleep(0.05)\n",
        "        except Exception as e:\n",
        "            print(f\"Error in transcription loop: {e}\", flush=True)\n",
        "\n",
        "    # Process any remaining audio in buffer before stopping\n",
        "    if len(full_audio_buffer) > 0:\n",
        "        with full_audio_buffer_lock:\n",
        "            remaining_segment = full_audio_buffer\n",
        "            full_audio_buffer = np.array([], dtype=DTYPE)\n",
        "        try:\n",
        "            if len(remaining_segment) > 0:\n",
        "                input_features = whisper_processor(remaining_segment, sampling_rate=SAMPLE_RATE, return_tensors=\"pt\").input_features\n",
        "                input_features = input_features.to(whisper_device)\n",
        "                predicted_ids = whisper_model.generate(input_features)\n",
        "                transcription = whisper_processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
        "                if transcription.strip() != \"\":\n",
        "                    print(f\"Final Transcribed: {transcription}\", flush=True)\n",
        "                    transcription_queue.put(transcription)\n",
        "        except Exception as e:\n",
        "            print(f\"Error during final transcription: {e}\", flush=True)\n",
        "    print(\"Transcription thread stopped.\")\n",
        "\n",
        "\n",
        "# --- VibeVoice Synthesis and Playback ---\n",
        "# This function encapsulates the core VibeVoice text-to-speech logic\n",
        "def _synthesize_and_play(text: str):\n",
        "    if not _vibevoice_model or not _vibevoice_processor:\n",
        "        print(f\"VibeVoice model not loaded, mocking synthesis for: '{text}'\", flush=True)\n",
        "        # Simulate some delay for synthesis\n",
        "        time.sleep(len(text) * 0.05)\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # Example VibeVoice synthesis process - actual API might differ\n",
        "        inputs = _vibevoice_processor(text=text, return_tensors=\"pt\").to(_vibevoice_device)\n",
        "        with torch.no_grad():\n",
        "            audio_array = _vibevoice_model.generate(**inputs).cpu().numpy().squeeze()\n",
        "\n",
        "        # Play the synthesized audio\n",
        "        print(f\"Playing VibeVoice synthesized audio for: '{text}'\", flush=True)\n",
        "        sd.play(audio_array, samplerate=_vibevoice_processor.sampling_rate)\n",
        "        sd.wait() # Wait for playback to finish\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during VibeVoice synthesis or playback: {e}\", flush=True)\n",
        "\n",
        "def vibevoice_synthesis_loop():\n",
        "    print(\"VibeVoice synthesis thread started.\")\n",
        "    while not stop_event.is_set():\n",
        "        try:\n",
        "            text_to_synthesize = transcription_queue.get(timeout=0.1) # Get with timeout\n",
        "            if text_to_synthesize:\n",
        "                print(f\"VibeVoice synthesizing: '{text_to_synthesize}'\", flush=True)\n",
        "                _synthesize_and_play(text_to_synthesize)\n",
        "        except queue.Empty:\n",
        "            pass # No transcription yet, continue looping\n",
        "        except Exception as e:\n",
        "            print(f\"Error in VibeVoice synthesis loop: {e}\", flush=True)\n",
        "    print(\"VibeVoice synthesis thread stopped.\")\n",
        "\n",
        "# --- FastAPI Application Setup ---\n",
        "app = FastAPI()\n",
        "\n",
        "class TextPayload(BaseModel):\n",
        "    text: str\n",
        "\n",
        "@app.post(\"/synthesize\")\n",
        "async def synthesize_text_api(payload: TextPayload):\n",
        "    # This endpoint allows external text to be synthesized\n",
        "    print(f\"API received text for synthesis: {payload.text}\", flush=True)\n",
        "    # The API call will also go through the internal synthesis logic\n",
        "    _synthesize_and_play(payload.text)\n",
        "    return {\"message\": f\"Synthesis request received for: {payload.text}\"}\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def root():\n",
        "    return {\"message\": \"VibeVoice Real-time Demo with Whisper integration is running!\"}\n",
        "\n",
        "# --- Main execution block ---\n",
        "# These threads need to be started before uvicorn.run blocks the main thread.\n",
        "transcription_thread = threading.Thread(target=transcription_loop, daemon=True)\n",
        "vibevoice_synthesis_thread = threading.Thread(target=vibevoice_synthesis_loop, daemon=True)\n",
        "\n",
        "@app.on_event(\"startup\")\n",
        "async def startup_event():\n",
        "    print(\"FastAPI startup event: Starting audio stream and threads...\")\n",
        "    global audio_stream\n",
        "    try:\n",
        "        audio_stream = sd.InputStream(\n",
        "            samplerate=SAMPLE_RATE,\n",
        "            channels=CHANNELS,\n",
        "            dtype=DTYPE,\n",
        "            blocksize=BLOCK_SIZE,\n",
        "            callback=audio_callback\n",
        "        )\n",
        "        audio_stream.start()\n",
        "        print(\"Audio input stream started.\")\n",
        "        transcription_thread.start()\n",
        "        vibevoice_synthesis_thread.start()\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to start audio stream or threads on startup: {e}\", flush=True)\n",
        "\n",
        "@app.on_event(\"shutdown\")\n",
        "async def shutdown_event():\n",
        "    print(\"FastAPI shutdown event: Stopping audio stream and threads...\")\n",
        "    stop_event.set()\n",
        "    if 'audio_stream' in globals() and audio_stream.is_active:\n",
        "        audio_stream.stop()\n",
        "        audio_stream.close()\n",
        "    if transcription_thread.is_alive():\n",
        "        transcription_thread.join(timeout=5)\n",
        "    if vibevoice_synthesis_thread.is_alive():\n",
        "        vibevoice_synthesis_thread.join(timeout=5)\n",
        "    print(\"Cleanup complete.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Uvicorn needs to be run programmatically to allow startup/shutdown events\n",
        "    print(f\"Starting Uvicorn server on port {args.port}...\")\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=args.port)\n"
      ],
      "id": "985f4ff6",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/VibeVoice/demo/vibevoice_realtime_demo.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c48ff22"
      },
      "source": [
        "**Reasoning**:\n",
        "The modified `vibevoice_realtime_demo.py` script needs to be executed to launch the VibeVoice-Realtime Demo with Whisper integration.\n",
        "\n"
      ],
      "id": "1c48ff22"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9670c00e",
        "outputId": "352f20a2-a271-43a4-b17d-d675ec4387dc"
      },
      "source": [
        "import subprocess, re, time, threading\n",
        "\n",
        "srv = subprocess.Popen(\n",
        "    \"python /content/VibeVoice/demo/vibevoice_realtime_demo.py --model_path /content/models/VibeVoice-Realtime-0.5B --port 8000\",\n",
        "    shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1, universal_newlines=True,\n",
        ")\n",
        "cf = subprocess.Popen(\n",
        "    \"./cloudflared tunnel --url http://localhost:8000 --no-autoupdate\",\n",
        "    shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1, universal_newlines=True,\n",
        ")\n",
        "\n",
        "public_url = None\n",
        "server_ready = False\n",
        "url_pattern  = re.compile(r\"(https://[a-z0-9-]+\\.trycloudflare\\.com)\")\n",
        "\n",
        "def read_srv():\n",
        "    global server_ready\n",
        "    for ln in srv.stdout:\n",
        "        print(ln.strip())\n",
        "        if \"Uvicorn running on\" in ln:\n",
        "            server_ready = True\n",
        "\n",
        "def read_cf():\n",
        "    global public_url\n",
        "    for ln in cf.stdout:\n",
        "        m = url_pattern.search(ln)\n",
        "        if m:\n",
        "            public_url = m.group(1)\n",
        "            break\n",
        "\n",
        "threading.Thread(target=read_srv, daemon=True).start()\n",
        "thr = threading.Thread(target=read_cf,  daemon=True).start()\n",
        "\n",
        "\n",
        "while True:\n",
        "    if server_ready and public_url:\n",
        "        print(f\"✅ Public URL: {public_url}\\n\");\n",
        "        public_url = None\n",
        "    time.sleep(0.25)"
      ],
      "id": "9670c00e",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "File \"/content/VibeVoice/demo/vibevoice_realtime_demo.py\", line 1, in <module>\n",
            "import sounddevice as sd\n",
            "File \"/usr/local/lib/python3.12/dist-packages/sounddevice.py\", line 71, in <module>\n",
            "raise OSError('PortAudio library not found')\n",
            "OSError: PortAudio library not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6ff4ab1"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous execution of `vibevoice_realtime_demo.py` failed because the `sounddevice` library could not find the PortAudio library. I need to install the PortAudio development files to resolve this dependency.\n",
        "\n"
      ],
      "id": "d6ff4ab1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44b451de",
        "outputId": "93a6347f-4068-4d91-f8fb-565fb4ace2c3"
      },
      "source": [
        "print(\"Installing PortAudio development files...\")\n",
        "!apt-get update -qq\n",
        "!apt-get install -y -qq portaudio19-dev\n",
        "print(\"✅ Installed PortAudio development files\")"
      ],
      "id": "44b451de",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing PortAudio development files...\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "dpkg: libjack-jackd2-0:amd64: dependency problems, but removing anyway as you requested:\n",
            " libavdevice58:amd64 depends on libjack-jackd2-0 (>= 1.9.10+20150825) | libjack-0.125; however:\n",
            "  Package libjack-jackd2-0:amd64 is to be removed.\n",
            "  Package libjack-0.125 is not installed.\n",
            "  Package libjack-jackd2-0:amd64 which provides libjack-0.125 is to be removed.\n",
            " libavdevice58:amd64 depends on libjack-jackd2-0 (>= 1.9.10+20150825) | libjack-0.125; however:\n",
            "  Package libjack-jackd2-0:amd64 is to be removed.\n",
            "  Package libjack-0.125 is not installed.\n",
            "  Package libjack-jackd2-0:amd64 which provides libjack-0.125 is to be removed.\n",
            "\n",
            "(Reading database ... 121689 files and directories currently installed.)\n",
            "Removing libjack-jackd2-0:amd64 (1.9.20~dfsg-1) ...\n",
            "Selecting previously unselected package libjack0:amd64.\n",
            "(Reading database ... 121679 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libjack0_1%3a0.125.0-3build2_amd64.deb ...\n",
            "Unpacking libjack0:amd64 (1:0.125.0-3build2) ...\n",
            "Selecting previously unselected package libasound2-dev:amd64.\n",
            "Preparing to unpack .../1-libasound2-dev_1.2.6.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libasound2-dev:amd64 (1.2.6.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libjack-dev.\n",
            "Preparing to unpack .../2-libjack-dev_1%3a0.125.0-3build2_amd64.deb ...\n",
            "Unpacking libjack-dev (1:0.125.0-3build2) ...\n",
            "Selecting previously unselected package libportaudio2:amd64.\n",
            "Preparing to unpack .../3-libportaudio2_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking libportaudio2:amd64 (19.6.0-1.1) ...\n",
            "Selecting previously unselected package libportaudiocpp0:amd64.\n",
            "Preparing to unpack .../4-libportaudiocpp0_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking libportaudiocpp0:amd64 (19.6.0-1.1) ...\n",
            "Selecting previously unselected package portaudio19-dev:amd64.\n",
            "Preparing to unpack .../5-portaudio19-dev_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking portaudio19-dev:amd64 (19.6.0-1.1) ...\n",
            "Setting up libjack0:amd64 (1:0.125.0-3build2) ...\n",
            "Setting up libjack-dev (1:0.125.0-3build2) ...\n",
            "Setting up libasound2-dev:amd64 (1.2.6.1-1ubuntu1) ...\n",
            "Setting up libportaudio2:amd64 (19.6.0-1.1) ...\n",
            "Setting up libportaudiocpp0:amd64 (19.6.0-1.1) ...\n",
            "Setting up portaudio19-dev:amd64 (19.6.0-1.1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "✅ Installed PortAudio development files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e1f086f"
      },
      "source": [
        "**Reasoning**:\n",
        "The PortAudio development files have been successfully installed. Now, I need to re-run the `vibevoice_realtime_demo.py` script to launch the VibeVoice-Realtime Demo with Whisper integration, as the previous attempt failed due to the missing PortAudio library.\n",
        "\n"
      ],
      "id": "8e1f086f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d45f677a",
        "outputId": "b871fbd0-9639-4766-c850-c8c00e224cec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import subprocess, re, time, threading\n",
        "\n",
        "srv = subprocess.Popen(\n",
        "    \"python /content/VibeVoice/demo/vibevoice_realtime_demo.py --model_path /content/models/VibeVoice-Realtime-0.5B --port 8000\",\n",
        "    shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1, universal_newlines=True,\n",
        ")\n",
        "cf = subprocess.Popen(\n",
        "    \"./cloudflared tunnel --url http://localhost:8000 --no-autoupdate\",\n",
        "    shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1, universal_newlines=True,\n",
        ")\n",
        "\n",
        "public_url = None\n",
        "server_ready = False\n",
        "url_pattern  = re.compile(r\"(https://[a-z0-9-]+\\.trycloudflare\\.com)\")\n",
        "\n",
        "def read_srv():\n",
        "    global server_ready\n",
        "    for ln in srv.stdout:\n",
        "        print(ln.strip())\n",
        "        if \"Uvicorn running on\" in ln:\n",
        "            server_ready = True\n",
        "\n",
        "def read_cf():\n",
        "    global public_url\n",
        "    for ln in cf.stdout:\n",
        "        m = url_pattern.search(ln)\n",
        "        if m:\n",
        "            public_url = m.group(1)\n",
        "            break\n",
        "\n",
        "threading.Thread(target=read_srv, daemon=True).start()\n",
        "thr = threading.Thread(target=read_cf,  daemon=True).start()\n",
        "\n",
        "\n",
        "while True:\n",
        "    if server_ready and public_url:\n",
        "        print(f\"✅ Public URL: {public_url}\\n\");\n",
        "        public_url = None\n",
        "    time.sleep(0.25)"
      ],
      "id": "d45f677a",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/VibeVoice/demo/vibevoice_realtime_demo.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "name": "VibeVoice_Colab.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}